{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwYBZUt99ddnLQfrCG+qr+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanga-v2/Transformers/blob/main/qwen3_8b_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAJst7zAyhK7"
      },
      "outputs": [],
      "source": [
        "#LLM fine-tuning\n",
        "\n",
        "# pre-requisites\n",
        "\n",
        "# let's take a pre-trained model - gpt, llama, qwen\n",
        "\n",
        "# datsets\n",
        "\n",
        "# framework - transformers arch ? ----> transfomer vs mamba ?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "RXVGskpkzh-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")"
      ],
      "metadata": {
        "id": "VKd7bDKVzmBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "ZQCWUwYe1nHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "id": "c4IPpNU-1wan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "RCb3spW9128e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('datsets/Interview_Data_6K.csv','r') as f:\n",
        "    data = f.read()\n",
        "\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "r5GJ6Nk_1VEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        " {\n",
        " \"title\": \"Achieving Controlled Nuclear Fusion\",\n",
        " \"text\": \"Nuclear fusion is the process by which atomic nuclei combine to form a heavier nucleus, releasing energy in the process. Researchers have been working towards achieving controlled nuclear fusion for decades, with the goal of creating a clean and sustainable source of energy.\",\n",
        " \"labels\": [\"nuclear fusion\", \"energy production\", \"plasma physics\"]\n",
        " },\n",
        " {\n",
        " \"title\": \"ITER: The International Thermonuclear Experimental Reactor\",\n",
        " \"text\": \"ITER is an international collaboration aimed at demonstrating the feasibility of nuclear fusion as a power source. The reactor is currently under construction in France and is expected to be operational by the mid-2020s.\",\n",
        " \"labels\": [\"ITER\", \"nuclear fusion reactor\", \"plasma confinement\"]\n",
        " },\n",
        " {\n",
        " \"title\": \"Magnetic Confinement Fusion\",\n",
        " \"text\": \"Magnetic confinement fusion is a technique used to contain and heat plasma in a controlled environment. This approach has shown promise in achieving controlled nuclear fusion.\",\n",
        " \"labels\": [\"magnetic confinement\", \"plasma physics\", \"nuclear fusion\"]\n",
        " },\n",
        " {\n",
        " \"title\": \"Inertial Confinement Fusion\",\n",
        " \"text\": \"Inertial confinement fusion is a technique that uses high-powered lasers or particle beams to compress and heat a small pellet of fusion fuel to achieve nuclear fusion.\",\n",
        " \"labels\": [\"inertial confinement\", \"laser-driven fusion\", \"nuclear fusion\"]\n",
        " }\n",
        "]\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to JSONL file\n",
        "df.to_json(\"nuclear_fusion_dataset.jsonl\", orient=\"records\", lines=True)"
      ],
      "metadata": {
        "id": "PA5EiK8Z11ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "HVFo3RAu5Fnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data_without_pt = tokenizer(df['text'].to_list(), truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "kvbQHBlJ5hV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_data_without_pt['input_ids'])"
      ],
      "metadata": {
        "id": "of7SMlqD58ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = tokenizer(df['text'].to_list(), truncation=True, padding=True,return_tensors='pt')"
      ],
      "metadata": {
        "id": "9fLl8lte6DZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_data['input_ids'])"
      ],
      "metadata": {
        "id": "1s1CZ-LK6IM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "b5CtE-k_7TAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TrainingArguments)"
      ],
      "metadata": {
        "id": "7y69ThWl7Z3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=32,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=5e-5, ## the lower the learn rate, it takes time but accuracy will be higher\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")"
      ],
      "metadata": {
        "id": "m6XU64WR7frW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer"
      ],
      "metadata": {
        "id": "rdpE66Ja8mcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Trainer)"
      ],
      "metadata": {
        "id": "C-366dge8pbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = tokenized_data\n",
        ")"
      ],
      "metadata": {
        "id": "zfuYymrs8rG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "LihnkDkR-wmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}